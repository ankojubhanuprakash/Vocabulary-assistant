# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SIfvcOFvoD1sw76Tm1YUFFXmNyrCdWnG
"""

from spacy.lang.en import English

# Load English tokenizer, tagger, parser, NER and word vectors
nlp = English()

text = """He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and 
fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had 
indeed the vaguest idea where the wood and river in question were."""

#  "nlp" Object is used to create documents with linguistic annotations.
my_doc = nlp(text)

# Create list of word tokens
token_list = []
for token in my_doc:
    token_list.append(token.text)

from spacy.lang.en.stop_words import STOP_WORDS

# Create list of word tokens after removing stopwords
filtered_sentence =[] 

for word in token_list:
    lexeme = nlp.vocab[word]
    if lexeme.is_stop == False:
        filtered_sentence.append(word) 
print(token_list)
print(filtered_sentence)

import pandas as pd
import requests
import numpy as np

pwd

ls

df=pd.read_csv("livevocab.csv")

df[100:,]

response = requests.get("https://api.dictionaryapi.dev/api/v2/entries/en/")
def getstuff(Word):
  url = "https://api.dictionaryapi.dev/api/v2/entries/en/"
  url = url+ Word

  try:
    #print(url)
    response = requests.get(url).json()[0]
    #print('1')
    a,b = np.nan,np.nan
    if 'meanings' in response:
      #print('hi')
      response = response['meanings'][0]
      if 'definitions' in response:
        response = response['definitions'][0]
        if 'definition' in response:
          a = response['definition']
        if 'example' in response:
          b = response['example']  

        return [a,b]
        
      else:
        return [np.nan,np.nan]
    else:
      return [np.nan,np.nan]

  except:
    return  [np.nan,np.nan]

masterlist = []
for row in df.iterrows():
  templist = []
  word = row[1]['Word']
  templist.append(word)
  result = getstuff(word)
  templist +=  result
  
  masterlist.append(templist)

colum = df.columns
colum

df_main=pd.DataFrame(data=masterlist,columns=colum)
df_main

df_main.to_csv('living.csv')

aa=response.json()[0]
bb=aa['meanings'][0]['def']
aa



if 'meanings' in aa:
  print('hi')

bb

